{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertModel\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased',\n",
    "                                                    truncation=True,padding='max_length',max_length=512)\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-disposal",
   "metadata": {},
   "source": [
    "# For 2 strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(file1, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state.mean(1)\n",
    "\n",
    "input =tokenizer(file2,return_tensors='pt')\n",
    "\n",
    "outputs1 = model(**input) \n",
    "last_hidden_states1 = outputs1.last_hidden_state.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "output = cos(last_hidden_states, last_hidden_states1)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-joint",
   "metadata": {},
   "source": [
    "# For a dataset where the text column is at \"0th\" Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "values={}\n",
    "for i in range(df.shape[0]):\n",
    "    ## Created a list to append the values w.r.t 1st text\n",
    "    list1=[]\n",
    "\n",
    "    ## Calculated last hidden state of 1st Text\n",
    "    v1=df.iloc[i,0]\n",
    "    inputs = tokenizer(v1, return_tensors=\"pt\",truncation=True,padding='max_length',max_length=512)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    last_hidden_states = outputs.last_hidden_state.mean(1)\n",
    "\n",
    "\n",
    "    ####### Calculate score w.r.t first text\n",
    "    for j in range(df.shape[0]):\n",
    "\n",
    "    ## Calculated last hidden state of 2nd Text\n",
    "    v2=df.iloc[j,0]\n",
    "    input =tokenizer(v2,return_tensors='pt',truncation=True,padding='max_length',max_length=512)\n",
    "\n",
    "    outputs1 = model(**input) \n",
    "    last_hidden_states1 = outputs1.last_hidden_state.mean(1)\n",
    "\n",
    "    ## Calculate the Cosine Distance between First Text and Second Text\n",
    "    output = cos(last_hidden_states, last_hidden_states1)\n",
    "\n",
    "    #Appending the value to list\n",
    "    list1.append(output.detach().numpy()[0])\n",
    "\n",
    "\n",
    "    values[str(i)]=list1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-legend",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
